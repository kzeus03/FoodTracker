from dotenv import load_dotenv
from langchain_groq import ChatGroq
import os
import pandas as pd
import re
import streamlit as st
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "..")))

load_dotenv()

llm = ChatGroq(groq_api_key=os.getenv("GROG_API_KEY"), model_name="llama-3.3-70b-versatile")

# add memory to the model for asking queries
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

st.title("Welcome to Calorie Tracker")

def get_calories(food):
    prompt = f'Get protein, fat, carbs, fiber, cholesterol for {food}. All values must be in terms of grams and the datatype must be either int or float. Display the result in a table format without extra explanations.'
    response = llm.invoke(prompt)
    table_rows = response.content.split("\n")
    pattern = r"\|\s*(\w+)\s*\|\s*([\d.]+)[a-zA-Z]*\s*\|"

    extracted_data = [re.findall(pattern, row) for row in table_rows]
    cleaned_data = [item[0] for item in extracted_data if item]

    clean_rows = []
    for item in cleaned_data:
        category, value = item
        clean_rows.append({"Category": category, "Grams": float(value)})

    df = pd.DataFrame(clean_rows)
    return df

# function to generate the recipe
def chef(food, df):
    prompt = f'Generate a simple recipe to prepare {food}. No explanations or preamble'
    response = llm.invoke(prompt)
    st.session_state.recipe_procedure = response.content
    col1, col2 = st.columns(2)

    with col1:
        st.write("#### Calorie Breakdown")
        st.dataframe(df)
    with col2:
        st.write("#### Visual Representation")
        st.bar_chart(df.set_index('Category'))

    st.header("How to make")
    st.write(response.content)
    st.header("Ask your questions here")
    user_query = st.chat_input("Ask anything: ")
    if user_query:
        ask_questions(user_query)

    if st.session_state.chat_history:
        st.write("### Chat History")
        for message in st.session_state.chat_history:
            if isinstance(message, dict) and "user" in message and "ai" in message:
                st.write(f"**User:** {message['user']}")
                st.write(f"**AI:** {message['ai']}")
            else:
                st.write(f"**User:** {message}")

# function to process user queries related to the recipe generated by the model
def ask_questions(user_query):
    procedure = st.session_state.get("recipe_procedure","")
    prompt = f"Recipe: {procedure}\n\nUser question: {user_query}. No preamble"
    response = llm.invoke(prompt).content
    st.session_state.chat_history.append({"user": user_query, "ai": response})
    st.rerun()

user_input = st.text_input("Enter a food item: ")
if user_input:
    data = get_calories(user_input)
    chef(user_input,data)